{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2819227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(r\"Areas-of-interest-POIs\\merged_building_volumes_filtered.gpkg\")\n",
    "\n",
    "print(gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse(r\"Areas-of-interest-POIs\\BuildingFunctionTypeAdV.xml\")\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9928d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def read_adv_codelist(xml_path):\n",
    "    ns = {\"gml\": \"http://www.opengis.net/gml\"}\n",
    "    root = ET.parse(xml_path).getroot()\n",
    "\n",
    "    rows = []\n",
    "    for d in root.findall(\".//gml:Definition\", ns):\n",
    "        code = None\n",
    "        label_de = None\n",
    "        for n in d.findall(\"gml:name\", ns):\n",
    "            if \"codeSpace\" in n.attrib:\n",
    "                code = (n.text or \"\").strip()\n",
    "            else:\n",
    "                label_de = (n.text or \"\").strip()\n",
    "        if code and label_de:\n",
    "            rows.append((code, label_de))\n",
    "\n",
    "    return (pd.DataFrame(rows, columns=[\"function\", \"label_de\"])\n",
    "              .drop_duplicates(\"function\")\n",
    "              .sort_values(\"function\")\n",
    "              .reset_index(drop=True))\n",
    "\n",
    "df_codes = read_adv_codelist(r\"Areas-of-interest-POIs\\BuildingFunctionTypeAdV.xml\")\n",
    "df_codes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_codes['label_de'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fafc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes['label_de'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ceaaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes.to_csv(\n",
    "    r\"Areas-of-interest-POIs\\building_function_codelist.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9108700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from googletrans import Translator\n",
    "\n",
    "# df = pd.read_csv(\n",
    "#     r\"Areas-of-interest-POIs\\building_function_codelist.csv\",\n",
    "#     encoding=\"utf-8-sig\"\n",
    "# )\n",
    "\n",
    "# translator = Translator()\n",
    "\n",
    "# def translate(text):\n",
    "#     if pd.isna(text):\n",
    "#         return text\n",
    "#     return translator.translate(text, src=\"de\", dest=\"en\").text\n",
    "\n",
    "# df[\"label_en\"] = df[\"label_de\"].apply(translate)\n",
    "\n",
    "# df.to_csv(\n",
    "#     r\"Areas-of-interest-POIs\\building_function_codelist_de_en.csv\",\n",
    "#     index=False,\n",
    "#     encoding=\"utf-8-sig\"\n",
    "# )\n",
    "\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02569785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"Areas-of-interest-POIs\\building_function_codelist_de_en.csv\")\n",
    "\n",
    "gdf = gdf.merge(\n",
    "    df[[\"function\", \"label_de\", \"label_en\"]],\n",
    "    on=\"function\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69748cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_building_data = gpd.read_file(r\"Areas-of-interest-POIs\\Buildings-Area-of-study.gpkg\")\n",
    "\n",
    "osm_building_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dcf762",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_building_data.to_crs(gdf.crs, inplace=True)\n",
    "print(osm_building_data.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b47e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_col = \"name\"  \n",
    "\n",
    "# keep only features that actually have a name\n",
    "osm_named = osm_building_data[osm_building_data[name_col].notna() & (osm_building_data[name_col].astype(str).str.strip() != \"\")].copy()\n",
    "\n",
    "# spatial join: which OSM buildings intersect each gdf polygon\n",
    "j = gpd.sjoin(\n",
    "    gdf[[\"geometry\"]].reset_index(names=\"gdf_idx\"),\n",
    "    osm_named[[name_col, \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"intersects\"\n",
    ")\n",
    "\n",
    "# aggregate names into unique list per gdf polygon\n",
    "names = (j.groupby(\"gdf_idx\")[name_col]\n",
    "           .apply(lambda s: sorted(set(str(x).strip() for x in s.dropna() if str(x).strip())))\n",
    "           .rename(\"osm_names\"))\n",
    "\n",
    "# attach back to gdf\n",
    "gdf[\"osm_names\"] = gdf.index.to_series().map(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf[\"osm_names\"].notna() & (gdf[\"osm_names\"].str.len() > 10)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a74831",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_landuse_data = gpd.read_file(r\"Areas-of-interest-POIs\\Land-use_Area-of-study.gpkg\")\n",
    "\n",
    "osm_landuse_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56c9959",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_landuse_data['fclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a53ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_landuse_data['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2abd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "landuse = osm_landuse_data.to_crs(gdf.crs)\n",
    "\n",
    "# spatial join\n",
    "j = gpd.sjoin(\n",
    "    gdf[[\"geometry\"]].reset_index(names=\"gdf_idx\"),\n",
    "    landuse[[\"fclass\", \"name\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"intersects\"\n",
    ")\n",
    "\n",
    "# aggregate landuse class\n",
    "class_lu = (\n",
    "    j.groupby(\"gdf_idx\")[\"fclass\"]\n",
    "     .apply(lambda s: sorted(set(x for x in s.dropna())))\n",
    ")\n",
    "\n",
    "# aggregate landuse name\n",
    "name_lu = (\n",
    "    j.groupby(\"gdf_idx\")[\"name\"]\n",
    "     .apply(lambda s: sorted(set(str(x).strip() for x in s.dropna() if str(x).strip())))\n",
    ")\n",
    "\n",
    "# attach to gdf (lists, empty list means no landuse intersected)\n",
    "gdf[\"class_landuse\"] = gdf.index.to_series().map(class_lu).apply(lambda x: x if isinstance(x, list) else [])\n",
    "gdf[\"name_landuse\"]  = gdf.index.to_series().map(name_lu).apply(lambda x: x if isinstance(x, list) else [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf[\"name_landuse\"].notna() & (gdf[\"name_landuse\"].str.len() > 0)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = pd.read_excel(\n",
    "    r\"Areas-of-interest-POIs\\alkis_building_activity_map.xlsx\"\n",
    ")\n",
    "\n",
    "gdf = gdf.merge(\n",
    "    df_map,\n",
    "    left_on=\"function\",\n",
    "    right_on=\"gfk_code\",\n",
    "    how=\"left\"\n",
    ").drop(columns=[\"gfk_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c94d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "residencial_ALKIS = gpd.read_file('Areas-of-interest-POIs/Residencial-Landuse_ALKIS.gpkg')\n",
    "print(residencial_ALKIS.crs)\n",
    "residencial_ALKIS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "residencial_ALKIS.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "residential = residencial_ALKIS[[\"geometry\"]].to_crs(gdf.crs)\n",
    "\n",
    "# Spatial join (building INSIDE residential polygon)\n",
    "j = gpd.sjoin(\n",
    "    gdf[[\"geometry\"]].reset_index(names=\"gdf_idx\"),\n",
    "    residential,\n",
    "    how=\"inner\",          # only include building polygons which are inside landuse polygons\n",
    "    # predicate=\"within\"\n",
    "    predicate=\"intersects\"\n",
    ")\n",
    "\n",
    "# Unique building indices that are residential\n",
    "res_idx = j[\"gdf_idx\"].unique()\n",
    "\n",
    "# 4) Create column with NaN by default\n",
    "gdf[\"ALKIS_Landuse_info\"] = np.nan\n",
    "\n",
    "# 5) Assign only matching buildings\n",
    "gdf.loc[res_idx, \"ALKIS_Landuse_info\"] = \"residence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5ce1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b7943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['ALKIS_Landuse_info'].value_counts(dropna=False)\n",
    "# 525479"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc598e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "commercial_ALKIS = gpd.read_file('Areas-of-interest-POIs/Commercial_Landuse_ALKIS.gpkg')\n",
    "print(commercial_ALKIS.crs)\n",
    "commercial_ALKIS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84423e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "commercial = commercial_ALKIS[[\"geometry\"]].to_crs(gdf.crs)\n",
    "\n",
    "j_com = gpd.sjoin(\n",
    "    gdf[[\"geometry\"]].reset_index(names=\"gdf_idx\"),\n",
    "    commercial,\n",
    "    how=\"inner\",\n",
    "    # predicate=\"within\"\n",
    "    predicate=\"intersects\"\n",
    ")\n",
    "\n",
    "com_idx = j_com[\"gdf_idx\"].unique()\n",
    "\n",
    "def to_list(v):\n",
    "    if isinstance(v, list):\n",
    "        return v\n",
    "    if v is np.nan or (isinstance(v, float) and np.isnan(v)):\n",
    "        return []\n",
    "    return [v]\n",
    "\n",
    "gdf[\"ALKIS_Landuse_info\"] = gdf[\"ALKIS_Landuse_info\"].apply(to_list)\n",
    "\n",
    "gdf.loc[com_idx, \"ALKIS_Landuse_info\"] = (\n",
    "    gdf.loc[com_idx, \"ALKIS_Landuse_info\"]\n",
    "    .apply(lambda lst: lst if \"commercial\" in lst else lst + [\"commercial\"])\n",
    ")\n",
    "\n",
    "gdf[\"ALKIS_Landuse_info\"] = gdf[\"ALKIS_Landuse_info\"].apply(\n",
    "    lambda x: np.nan if isinstance(x, list) and len(x) == 0 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd0ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b0abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['ALKIS_Landuse_info'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2271d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "industries_ALKIS = gpd.read_file('Areas-of-interest-POIs/Industries_Landuse_ALKIS.gpkg')\n",
    "print(industries_ALKIS.crs)\n",
    "industries_ALKIS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "industries = industries_ALKIS[[\"geometry\"]].to_crs(gdf.crs)\n",
    "\n",
    "j_ind = gpd.sjoin(\n",
    "    gdf[[\"geometry\"]].reset_index(names=\"gdf_idx\"),\n",
    "    industries,\n",
    "    how=\"inner\",\n",
    "    predicate=\"intersects\"\n",
    "    # predicate=\"within\"\n",
    ")\n",
    "\n",
    "ind_idx = j_ind[\"gdf_idx\"].unique()\n",
    "\n",
    "def to_list(v):\n",
    "    if isinstance(v, list):\n",
    "        return v\n",
    "    if v is np.nan or (isinstance(v, float) and np.isnan(v)):\n",
    "        return []\n",
    "    return [v]\n",
    "\n",
    "gdf[\"ALKIS_Landuse_info\"] = gdf[\"ALKIS_Landuse_info\"].apply(to_list)\n",
    "\n",
    "gdf.loc[ind_idx, \"ALKIS_Landuse_info\"] = (\n",
    "    gdf.loc[ind_idx, \"ALKIS_Landuse_info\"]\n",
    "    .apply(lambda lst: lst if \"industrial\" in lst else lst + [\"industrial\"])\n",
    ")\n",
    "\n",
    "gdf[\"ALKIS_Landuse_info\"] = gdf[\"ALKIS_Landuse_info\"].apply(\n",
    "    lambda x: np.nan if isinstance(x, list) and len(x) == 0 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4fbd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4aef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['ALKIS_Landuse_info'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d12725",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_office_ALKIS = gpd.read_file('Areas-of-interest-POIs/Public-office_Landuse_ALKIS.gpkg')\n",
    "print(public_office_ALKIS.crs)\n",
    "public_office_ALKIS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8be15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_office = public_office_ALKIS[[\"geometry\"]].to_crs(gdf.crs)\n",
    "\n",
    "j_pub = gpd.sjoin(\n",
    "    gdf[[\"geometry\"]].reset_index(names=\"gdf_idx\"),\n",
    "    public_office,\n",
    "    how=\"inner\",\n",
    "    # predicate=\"within\"\n",
    "    predicate=\"intersects\"\n",
    ")\n",
    "\n",
    "pub_idx = j_pub[\"gdf_idx\"].unique()\n",
    "\n",
    "def to_list(v):\n",
    "    if isinstance(v, list):\n",
    "        return v\n",
    "    if v is np.nan or (isinstance(v, float) and np.isnan(v)):\n",
    "        return []\n",
    "    return [v]\n",
    "\n",
    "gdf[\"ALKIS_Landuse_info\"] = gdf[\"ALKIS_Landuse_info\"].apply(to_list)\n",
    "\n",
    "gdf.loc[pub_idx, \"ALKIS_Landuse_info\"] = (\n",
    "    gdf.loc[pub_idx, \"ALKIS_Landuse_info\"]\n",
    "    .apply(lambda lst: lst if \"public_office\" in lst else lst + [\"public_office\"])\n",
    ")\n",
    "\n",
    "gdf[\"ALKIS_Landuse_info\"] = gdf[\"ALKIS_Landuse_info\"].apply(\n",
    "    lambda x: np.nan if isinstance(x, list) and len(x) == 0 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab377dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['ALKIS_Landuse_info'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5983cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_ALKIS = gpd.read_file('Areas-of-interest-POIs/Sports-area_Landuse_ALKIS.gpkg')\n",
    "print(sport_ALKIS.crs)\n",
    "sport_ALKIS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport = sport_ALKIS[[\"geometry\"]].to_crs(gdf.crs)\n",
    "\n",
    "j_sport = gpd.sjoin(\n",
    "    gdf[[\"geometry\"]].reset_index(names=\"gdf_idx\"),\n",
    "    sport,\n",
    "    how=\"inner\",\n",
    "    # predicate=\"within\"\n",
    "    predicate=\"intersects\"\n",
    ")\n",
    "\n",
    "sport_idx = j_sport[\"gdf_idx\"].unique()\n",
    "\n",
    "def to_list(v):\n",
    "    if isinstance(v, list):\n",
    "        return v\n",
    "    if v is np.nan or (isinstance(v, float) and np.isnan(v)):\n",
    "        return []\n",
    "    return [v]\n",
    "\n",
    "gdf[\"ALKIS_Landuse_info\"] = gdf[\"ALKIS_Landuse_info\"].apply(to_list)\n",
    "\n",
    "gdf.loc[sport_idx, \"ALKIS_Landuse_info\"] = (\n",
    "    gdf.loc[sport_idx, \"ALKIS_Landuse_info\"]\n",
    "    .apply(lambda lst: lst if \"sport\" in lst else lst + [\"sport\"])\n",
    ")\n",
    "\n",
    "gdf[\"ALKIS_Landuse_info\"] = gdf[\"ALKIS_Landuse_info\"].apply(\n",
    "    lambda x: np.nan if isinstance(x, list) and len(x) == 0 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['ALKIS_Landuse_info'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf['ALKIS_Landuse_info'].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3764f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf[gdf['ALKIS_Landuse_info'].isna()].to_file('Buildings-with-no-ALKIS-tags-intersect.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f07f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf[gdf['ALKIS_Landuse_info'].isna()].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1360679",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c4671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be69847",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf['label_en'].isna())/len(gdf)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c26f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf['osm_names'].notna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfdb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['gfk_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19277600",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = gdf.sample(n=50)\n",
    "\n",
    "random_samples = random_samples[['gml_id', 'Stadt', 'Strasse', 'HausNr', 'Name', \n",
    "                                 'area_m2', 'volume_m3', 'geometry', 'label_de', 'label_en', \n",
    "                                 'osm_names', 'class_landuse', 'name_landuse','gfk_class',\n",
    "                                 'gfk_name', 'ALKIS_Landuse_info']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d53115",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e219500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "HF_TOKEN = \"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\"\n",
    "\n",
    "r = requests.get(\n",
    "    \"https://router.huggingface.co/v1/models\",\n",
    "    headers={\"Authorization\": f\"Bearer {HF_TOKEN}\"},\n",
    "    timeout=30,\n",
    ")\n",
    "\n",
    "print(\"STATUS:\", r.status_code)\n",
    "print(r.text[:500])\n",
    "r.raise_for_status()\n",
    "\n",
    "data = r.json()\n",
    "print(\"Models returned:\", len(data.get(\"data\", [])))\n",
    "for m in data.get(\"data\", [])[:30]:\n",
    "    print(m.get(\"id\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Final runnable script: classify each row of `random_sample` using HF Router + Llama 3.1 8B Instruct.\n",
    "\n",
    "- Sends ONE row at a time (as JSON) to the model\n",
    "- Model must return ONLY valid JSON: {\"gml_id\": ..., \"labels\": [...], \"short_reason\": \"...\"}\n",
    "- Multi-label allowed; empty list allowed\n",
    "- Drops heavy geometry by default\n",
    "- Robust JSON parsing + retry logic\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import ast\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "MODEL = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "URL = \"https://router.huggingface.co/v1/chat/completions\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {HF_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "TARGET_LABELS = [\n",
    "    \"workplace\",\n",
    "    \"university\",\n",
    "    \"kindergarden\",\n",
    "    \"shopping (non essential)\",\n",
    "    \"essentials activity\",\n",
    "    \"leisure\",\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# DETAILED SYSTEM PROMPT\n",
    "# -------------------------\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "You are an expert annotator for urban building function classification.\n",
    "\n",
    "You will be given ONE building record as JSON with fields like:\n",
    "- gml_id (unique building id)\n",
    "- city/address fields (Stadt, Strasse/Road, HausNr)\n",
    "- names (Name, label_de, label_en, osm_names)\n",
    "- landuse hints (class_landuse, name_landuse, ALKIS_Landuse_info, gfk_class, gfk_name)\n",
    "- size proxies (area_m2, volume_m3)\n",
    "Some fields may be missing (null) or empty lists.\n",
    "\n",
    "Your task:\n",
    "Assign ZERO OR MORE labels from this exact allowed list:\n",
    "{TARGET_LABELS}\n",
    "\n",
    "Important:\n",
    "- Think holistically: interpret the record like a human reading a bundle of clues.\n",
    "- Do NOT blindly trust any single field (landuse/ALKIS/gfk may be misleading or generic).\n",
    "- Prefer the real-world \"what people go there for\" function when possible.\n",
    "- Multi-label is allowed ONLY when the building genuinely supports multiple functions.\n",
    "- If there is not enough evidence for any label, return an empty list [].\n",
    "\n",
    "Label meanings (use these interpretations):\n",
    "- workplace: office/administration/industrial/logistics/production/company premises.\n",
    "- university: university, campus buildings, institutes, lecture halls, mensa/student services strongly tied to higher education.\n",
    "- kindergarden: Kita, Kindergarten, Krippe, daycare, early childhood education facilities.\n",
    "- essentials activity: everyday essential services (supermarket/grocery, pharmacy, doctor/clinic/hospital, basic banking/post, etc.).\n",
    "- shopping (non essential): retail that is typically discretionary (fashion, electronics, furniture, specialty retail).\n",
    "- leisure: recreation/culture/sport/entertainment (sports facilities, gyms, riding halls, museums, theaters, cinemas, etc.).\n",
    "\n",
    "Output format STRICTNESS:\n",
    "Return ONLY valid JSON. No markdown. No extra text.\n",
    "Must be exactly:\n",
    "{{\n",
    "  \"gml_id\": \"<string or number as provided>\",\n",
    "  \"labels\": [\"<zero or more labels from the allowed list>\"],\n",
    "  \"short_reason\": \"<one short sentence explaining the main evidence>\"\n",
    "}}\n",
    "\n",
    "Validation rules:\n",
    "- \"labels\" must be an array.\n",
    "- Each label must match one of the allowed labels EXACTLY.\n",
    "- short_reason should be concise (max ~25 words).\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------\n",
    "# HELPERS\n",
    "# -------------------------\n",
    "def safe_to_jsonable(v):\n",
    "    \"\"\"Convert NaNs and numpy types; keep lists/dicts; try parse list-like strings.\"\"\"\n",
    "    if v is None:\n",
    "        return None\n",
    "    # pandas NaN\n",
    "    try:\n",
    "        if pd.isna(v):\n",
    "            return None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Convert numpy scalars to python scalars\n",
    "    if hasattr(v, \"item\") and callable(v.item):\n",
    "        try:\n",
    "            return v.item()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # If it's already list/dict\n",
    "    if isinstance(v, (list, dict)):\n",
    "        return v\n",
    "\n",
    "    # Try parse strings that look like lists: \"['a','b']\"\n",
    "    if isinstance(v, str):\n",
    "        s = v.strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(s)\n",
    "                if isinstance(parsed, list):\n",
    "                    return parsed\n",
    "            except Exception:\n",
    "                return v\n",
    "    return v\n",
    "\n",
    "\n",
    "def row_to_prompt_dict(row: pd.Series, drop_geometry=True) -> dict:\n",
    "    d = {}\n",
    "    for k, v in row.to_dict().items():\n",
    "        if drop_geometry and k.lower() == \"geometry\":\n",
    "            continue\n",
    "        d[k] = safe_to_jsonable(v)\n",
    "    return d\n",
    "\n",
    "\n",
    "def build_messages(row_dict: dict):\n",
    "    user_content = (\n",
    "        \"Classify this building record.\\n\"\n",
    "        f\"Allowed labels: {TARGET_LABELS}\\n\\n\"\n",
    "        \"Building record (JSON):\\n\"\n",
    "        + json.dumps(row_dict, ensure_ascii=False)\n",
    "        + \"\\n\\nReturn only JSON.\"\n",
    "    )\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT.strip()},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "\n",
    "\n",
    "def extract_json_object(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Some models may accidentally wrap JSON in extra text.\n",
    "    This extracts the first top-level JSON object {...}.\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    # If it's already pure JSON object\n",
    "    if text.startswith(\"{\") and text.endswith(\"}\"):\n",
    "        return text\n",
    "\n",
    "    # Fallback: find first {...} block\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"No JSON object found in model output.\")\n",
    "    return m.group(0)\n",
    "\n",
    "\n",
    "def validate_result(obj: dict, original_gml_id):\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"Result is not a JSON object.\")\n",
    "    if \"gml_id\" not in obj or \"labels\" not in obj or \"short_reason\" not in obj:\n",
    "        raise ValueError(\"Missing required keys (gml_id, labels, short_reason).\")\n",
    "    if not isinstance(obj[\"labels\"], list):\n",
    "        raise ValueError('\"labels\" must be a list.')\n",
    "    for lab in obj[\"labels\"]:\n",
    "        if lab not in TARGET_LABELS:\n",
    "            raise ValueError(f'Invalid label: {lab}')\n",
    "    # Keep gml_id consistent if possible\n",
    "    # (We won't fail hard if type differs, but we try to preserve original)\n",
    "    return True\n",
    "\n",
    "\n",
    "def classify_row_with_llm(row_dict: dict, max_retries=3, backoff_sec=2.0):\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": build_messages(row_dict),\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 300,\n",
    "    }\n",
    "\n",
    "    original_gml_id = row_dict.get(\"gml_id\", None)\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            r = requests.post(URL, headers=HEADERS, json=payload, timeout=60)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "            json_str = extract_json_object(content)\n",
    "            obj = json.loads(json_str)\n",
    "            validate_result(obj, original_gml_id)\n",
    "            return obj\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            # small backoff then retry\n",
    "            time.sleep(backoff_sec * attempt)\n",
    "\n",
    "    raise RuntimeError(f\"Failed to classify row after {max_retries} retries: {last_err}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# MAIN: classify random_sample\n",
    "# -------------------------\n",
    "# Expect you already have: random_sample = <your dataframe>\n",
    "# Example:\n",
    "# random_sample = pd.read_csv(\"your_file.csv\")\n",
    "\n",
    "def classify_dataframe(random_sample: pd.DataFrame) -> pd.DataFrame:\n",
    "    assigned = []\n",
    "    reasons = []\n",
    "\n",
    "    for idx, row in random_samples.iterrows():\n",
    "        row_dict = row_to_prompt_dict(row, drop_geometry=True)\n",
    "        result = classify_row_with_llm(row_dict)\n",
    "\n",
    "        assigned.append(result.get(\"labels\", []))\n",
    "        reasons.append(result.get(\"short_reason\", \"\"))\n",
    "\n",
    "        # Optional: progress print\n",
    "        if (len(assigned) % 10) == 0:\n",
    "            print(f\"Classified {len(assigned)} / {len(random_samples)} rows...\")\n",
    "\n",
    "    out = random_samples.copy()\n",
    "    out[\"assigned_classes\"] = assigned\n",
    "    out[\"llm_reasoning\"] = reasons\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---- RUN ----\n",
    "classified_df = classify_dataframe(random_samples)\n",
    "# classified_df.to_csv(\"random_sample_classified.csv\", index=False)\n",
    "# print(\"Saved -> random_sample_classified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae7323",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium.features import GeoJsonTooltip\n",
    "\n",
    "df2 =classified_df.copy()\n",
    "\n",
    "# robust geometry handling\n",
    "geom_col = next((c for c in df2.columns if str(c).strip().lower() in [\"geometry\",\"geom\",\"wkt\",\"the_geom\"]), None)\n",
    "if geom_col is None:\n",
    "    raise ValueError(f\"No geometry column found. Columns: {list(df2.columns)}\")\n",
    "if geom_col != \"geometry\":\n",
    "    df2 = df2.rename(columns={geom_col: \"geometry\"})\n",
    "\n",
    "if pd.api.types.is_string_dtype(df2[\"geometry\"]):\n",
    "    df2[\"geometry\"] = gpd.GeoSeries.from_wkt(df2[\"geometry\"])\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df2, geometry=\"geometry\")\n",
    "gdf = gdf[~gdf.geometry.isna()].copy()\n",
    "gdf[\"geometry\"] = gdf.geometry.buffer(0)\n",
    "\n",
    "if gdf.crs is None:\n",
    "    gdf = gdf.set_crs(25832, allow_override=True)\n",
    "\n",
    "gdf = gdf.to_crs(4326)\n",
    "\n",
    "# flatten list column for styling/tooltip\n",
    "if \"assigned_classes\" in gdf.columns:\n",
    "    gdf[\"assigned_class\"] = gdf[\"assigned_classes\"].apply(\n",
    "        lambda x: x[0] if isinstance(x, list) and len(x) else \"unknown\"\n",
    "    )\n",
    "else:\n",
    "    gdf[\"assigned_class\"] = \"unknown\"\n",
    "\n",
    "# center map\n",
    "c = gdf.geometry.centroid\n",
    "m = folium.Map(location=[float(c.y.mean()), float(c.x.mean())], zoom_start=11, tiles=\"OpenStreetMap\")\n",
    "\n",
    "tooltip_cols = [c for c in [\"gml_id\",\"Stadt\",\"Strasse\",\"HausNr\",\"label_en\",\"area_m2\",\"volume_m3\",\"assigned_class\"] if c in gdf.columns]\n",
    "\n",
    "folium.GeoJson(\n",
    "    gdf,\n",
    "    name=\"buildings\",\n",
    "    style_function=lambda feat: {\"weight\": 1, \"fillOpacity\": 0.5},\n",
    "    tooltip=GeoJsonTooltip(fields=tooltip_cols, aliases=tooltip_cols, sticky=False)\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m  # in notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e88991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
