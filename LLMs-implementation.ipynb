{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31adb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_samples = gdf.sample(n=10)\n",
    "\n",
    "# random_samples = random_samples[['gml_id', 'Stadt', 'Strasse', 'HausNr', 'Name', \n",
    "#                                  'area_m2', 'volume_m3', 'geometry', 'label_de', 'label_en', \n",
    "#                                  'osm_names', 'class_landuse', 'name_landuse','gfk_class',\n",
    "#                                  'gfk_name', 'ALKIS_Landuse_info']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653f4a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc53f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# HF_TOKEN = \"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\"\n",
    "\n",
    "# r = requests.get(\n",
    "#     \"https://router.huggingface.co/v1/models\",\n",
    "#     headers={\"Authorization\": f\"Bearer {HF_TOKEN}\"},\n",
    "#     timeout=30,\n",
    "# )\n",
    "\n",
    "# print(\"STATUS:\", r.status_code)\n",
    "# print(r.text[:500])\n",
    "# r.raise_for_status()\n",
    "\n",
    "# data = r.json()\n",
    "# print(\"Models returned:\", len(data.get(\"data\", [])))\n",
    "# for m in data.get(\"data\", [])[:30]:\n",
    "#     print(m.get(\"id\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ef8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Final runnable script: classify each row of `random_sample` using HF Router + Llama 3.1 8B Instruct.\n",
    "\n",
    "# - Sends ONE row at a time (as JSON) to the model\n",
    "# - Model must return ONLY valid JSON: {\"gml_id\": ..., \"labels\": [...], \"short_reason\": \"...\"}\n",
    "# - Multi-label allowed; empty list allowed\n",
    "# - Drops heavy geometry by default\n",
    "# - Robust JSON parsing + retry logic\n",
    "# \"\"\"\n",
    "\n",
    "# import json\n",
    "# import time\n",
    "# import re\n",
    "# import ast\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "\n",
    "# # -------------------------\n",
    "# # CONFIG\n",
    "# # -------------------------\n",
    "# MODEL = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# URL = \"https://router.huggingface.co/v1/chat/completions\"\n",
    "\n",
    "# HEADERS = {\n",
    "#     \"Authorization\": f\"Bearer {HF_TOKEN}\",\n",
    "#     \"Content-Type\": \"application/json\",\n",
    "# }\n",
    "\n",
    "# TARGET_LABELS = [\n",
    "#     \"workplace\",\n",
    "#     \"university\",\n",
    "#     \"kindergarden\",\n",
    "#     \"shopping (non essential)\",\n",
    "#     \"essentials activity\",\n",
    "#     \"leisure\",\n",
    "# ]\n",
    "\n",
    "# # -------------------------\n",
    "# # DETAILED SYSTEM PROMPT\n",
    "# # -------------------------\n",
    "# SYSTEM_PROMPT = f\"\"\"\n",
    "# You are an expert annotator for urban building function classification.\n",
    "\n",
    "# You will be given ONE building record as JSON with fields like:\n",
    "# - gml_id (unique building id)\n",
    "# - city/address fields (Stadt, Strasse/Road, HausNr)\n",
    "# - names (Name, label_de, label_en, osm_names)\n",
    "# - landuse hints (class_landuse, name_landuse, ALKIS_Landuse_info, gfk_class, gfk_name)\n",
    "# - size proxies (area_m2, volume_m3)\n",
    "# Some fields may be missing (null) or empty lists.\n",
    "\n",
    "# Your task:\n",
    "# Assign ZERO OR MORE labels from this exact allowed list:\n",
    "# {TARGET_LABELS}\n",
    "\n",
    "# Important:\n",
    "# - Think holistically: interpret the record like a human reading a bundle of clues.\n",
    "# - Do NOT blindly trust any single field (landuse/ALKIS/gfk may be misleading or generic).\n",
    "# - Prefer the real-world \"what people go there for\" function when possible.\n",
    "# - Multi-label is allowed ONLY when the building genuinely supports multiple functions.\n",
    "# - If there is not enough evidence for any label, return an empty list [].\n",
    "\n",
    "# Label meanings (use these interpretations):\n",
    "# - workplace: office/administration/industrial/logistics/production/company premises.\n",
    "# - university: university, campus buildings, institutes, lecture halls, mensa/student services strongly tied to higher education.\n",
    "# - kindergarden: Kita, Kindergarten, Krippe, daycare, early childhood education facilities.\n",
    "# - essentials activity: everyday essential services (supermarket/grocery, pharmacy, doctor/clinic/hospital, basic banking/post, etc.).\n",
    "# - shopping (non essential): retail that is typically discretionary (fashion, electronics, furniture, specialty retail).\n",
    "# - leisure: recreation/culture/sport/entertainment (sports facilities, gyms, riding halls, museums, theaters, cinemas, etc.).\n",
    "\n",
    "# Output format STRICTNESS:\n",
    "# Return ONLY valid JSON. No markdown. No extra text.\n",
    "# Must be exactly:\n",
    "# {{\n",
    "#   \"gml_id\": \"<string or number as provided>\",\n",
    "#   \"labels\": [\"<zero or more labels from the allowed list>\"],\n",
    "#   \"short_reason\": \"<one short sentence explaining the main evidence>\"\n",
    "# }}\n",
    "\n",
    "# Validation rules:\n",
    "# - \"labels\" must be an array.\n",
    "# - Each label must match one of the allowed labels EXACTLY.\n",
    "# - short_reason should be concise (max ~25 words).\n",
    "# \"\"\"\n",
    "\n",
    "# # -------------------------\n",
    "# # HELPERS\n",
    "# # -------------------------\n",
    "# def safe_to_jsonable(v):\n",
    "#     \"\"\"Convert NaNs and numpy types; keep lists/dicts; try parse list-like strings.\"\"\"\n",
    "#     if v is None:\n",
    "#         return None\n",
    "#     # pandas NaN\n",
    "#     try:\n",
    "#         if pd.isna(v):\n",
    "#             return None\n",
    "#     except Exception:\n",
    "#         pass\n",
    "\n",
    "#     # Convert numpy scalars to python scalars\n",
    "#     if hasattr(v, \"item\") and callable(v.item):\n",
    "#         try:\n",
    "#             return v.item()\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "#     # If it's already list/dict\n",
    "#     if isinstance(v, (list, dict)):\n",
    "#         return v\n",
    "\n",
    "#     # Try parse strings that look like lists: \"['a','b']\"\n",
    "#     if isinstance(v, str):\n",
    "#         s = v.strip()\n",
    "#         if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "#             try:\n",
    "#                 parsed = ast.literal_eval(s)\n",
    "#                 if isinstance(parsed, list):\n",
    "#                     return parsed\n",
    "#             except Exception:\n",
    "#                 return v\n",
    "#     return v\n",
    "\n",
    "\n",
    "# def row_to_prompt_dict(row: pd.Series, drop_geometry=True) -> dict:\n",
    "#     d = {}\n",
    "#     for k, v in row.to_dict().items():\n",
    "#         if drop_geometry and k.lower() == \"geometry\":\n",
    "#             continue\n",
    "#         d[k] = safe_to_jsonable(v)\n",
    "#     return d\n",
    "\n",
    "\n",
    "# def build_messages(row_dict: dict):\n",
    "#     user_content = (\n",
    "#         \"Classify this building record.\\n\"\n",
    "#         f\"Allowed labels: {TARGET_LABELS}\\n\\n\"\n",
    "#         \"Building record (JSON):\\n\"\n",
    "#         + json.dumps(row_dict, ensure_ascii=False)\n",
    "#         + \"\\n\\nReturn only JSON.\"\n",
    "#     )\n",
    "#     return [\n",
    "#         {\"role\": \"system\", \"content\": SYSTEM_PROMPT.strip()},\n",
    "#         {\"role\": \"user\", \"content\": user_content},\n",
    "#     ]\n",
    "\n",
    "\n",
    "# def extract_json_object(text: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Some models may accidentally wrap JSON in extra text.\n",
    "#     This extracts the first top-level JSON object {...}.\n",
    "#     \"\"\"\n",
    "#     text = text.strip()\n",
    "#     # If it's already pure JSON object\n",
    "#     if text.startswith(\"{\") and text.endswith(\"}\"):\n",
    "#         return text\n",
    "\n",
    "#     # Fallback: find first {...} block\n",
    "#     m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "#     if not m:\n",
    "#         raise ValueError(\"No JSON object found in model output.\")\n",
    "#     return m.group(0)\n",
    "\n",
    "\n",
    "# def validate_result(obj: dict, original_gml_id):\n",
    "#     if not isinstance(obj, dict):\n",
    "#         raise ValueError(\"Result is not a JSON object.\")\n",
    "#     if \"gml_id\" not in obj or \"labels\" not in obj or \"short_reason\" not in obj:\n",
    "#         raise ValueError(\"Missing required keys (gml_id, labels, short_reason).\")\n",
    "#     if not isinstance(obj[\"labels\"], list):\n",
    "#         raise ValueError('\"labels\" must be a list.')\n",
    "#     for lab in obj[\"labels\"]:\n",
    "#         if lab not in TARGET_LABELS:\n",
    "#             raise ValueError(f'Invalid label: {lab}')\n",
    "#     # Keep gml_id consistent if possible\n",
    "#     # (We won't fail hard if type differs, but we try to preserve original)\n",
    "#     return True\n",
    "\n",
    "\n",
    "# def classify_row_with_llm(row_dict: dict, max_retries=3, backoff_sec=2.0):\n",
    "#     payload = {\n",
    "#         \"model\": MODEL,\n",
    "#         \"messages\": build_messages(row_dict),\n",
    "#         \"temperature\": 0.2,\n",
    "#         \"max_tokens\": 300,\n",
    "#     }\n",
    "\n",
    "#     original_gml_id = row_dict.get(\"gml_id\", None)\n",
    "\n",
    "#     last_err = None\n",
    "#     for attempt in range(1, max_retries + 1):\n",
    "#         try:\n",
    "#             r = requests.post(URL, headers=HEADERS, json=payload, timeout=60)\n",
    "#             r.raise_for_status()\n",
    "#             data = r.json()\n",
    "#             content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "#             json_str = extract_json_object(content)\n",
    "#             obj = json.loads(json_str)\n",
    "#             validate_result(obj, original_gml_id)\n",
    "#             return obj\n",
    "#         except Exception as e:\n",
    "#             last_err = e\n",
    "#             # small backoff then retry\n",
    "#             time.sleep(backoff_sec * attempt)\n",
    "\n",
    "#     raise RuntimeError(f\"Failed to classify row after {max_retries} retries: {last_err}\")\n",
    "\n",
    "\n",
    "# # -------------------------\n",
    "# # MAIN: classify random_sample\n",
    "# # -------------------------\n",
    "# # Expect you already have: random_sample = <your dataframe>\n",
    "# # Example:\n",
    "# # random_sample = pd.read_csv(\"your_file.csv\")\n",
    "\n",
    "# def classify_dataframe(random_sample: pd.DataFrame) -> pd.DataFrame:\n",
    "#     assigned = []\n",
    "#     reasons = []\n",
    "\n",
    "#     for idx, row in random_samples.iterrows():\n",
    "#         row_dict = row_to_prompt_dict(row, drop_geometry=True)\n",
    "#         result = classify_row_with_llm(row_dict)\n",
    "\n",
    "#         assigned.append(result.get(\"labels\", []))\n",
    "#         reasons.append(result.get(\"short_reason\", \"\"))\n",
    "\n",
    "#         # Optional: progress print\n",
    "#         if (len(assigned) % 10) == 0:\n",
    "#             print(f\"Classified {len(assigned)} / {len(random_samples)} rows...\")\n",
    "\n",
    "#     out = random_samples.copy()\n",
    "#     out[\"assigned_classes\"] = assigned\n",
    "#     out[\"llm_reasoning\"] = reasons\n",
    "#     return out\n",
    "\n",
    "\n",
    "# # ---- RUN ----\n",
    "# classified_df = classify_dataframe(random_samples)\n",
    "# # classified_df.to_csv(\"random_sample_classified.csv\", index=False)\n",
    "# # print(\"Saved -> random_sample_classified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cefd64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classified_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
